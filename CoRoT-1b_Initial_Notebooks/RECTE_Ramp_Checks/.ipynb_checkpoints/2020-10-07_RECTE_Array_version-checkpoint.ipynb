{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1006\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1006\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.0.min.js\": \"YobFyzPeVUsFQydHkJGsJL1kyfHnWxOlPc3EwaV22TmBaeGoXHLWx5aRRVPS9xlE\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.0.min.js\": \"NuAg9+TcTQQqvQCTtkCneRrpkTiMhhfiq0KHiBzx8ECiKiLWXHN6i6ia3q7b3eHu\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.0.min.js\": \"uMVqQc8JqHitD67bXTn9a06Mrk3EiHRaZ18EJENQenAKJ/KL71SakdXYomZQpGRr\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.0.min.js\": \"u+eGuEXC8aw0VSCm2mH+b/tQEAitUOYiR1H6SuIVEdUmXsf4vN8m/SmXpmjb7U/X\"};\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.0.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1006\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1006\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.0.min.js\": \"YobFyzPeVUsFQydHkJGsJL1kyfHnWxOlPc3EwaV22TmBaeGoXHLWx5aRRVPS9xlE\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.0.min.js\": \"NuAg9+TcTQQqvQCTtkCneRrpkTiMhhfiq0KHiBzx8ECiKiLWXHN6i6ia3q7b3eHu\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.0.min.js\": \"uMVqQc8JqHitD67bXTn9a06Mrk3EiHRaZ18EJENQenAKJ/KL71SakdXYomZQpGRr\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.0.min.js\": \"u+eGuEXC8aw0VSCm2mH+b/tQEAitUOYiR1H6SuIVEdUmXsf4vN8m/SmXpmjb7U/X\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.0.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1006\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "#import the module\n",
    "from __future__ import division, absolute_import\n",
    "from __future__ import print_function\n",
    "import itertools\n",
    "\n",
    "from tshirt.pipeline import spec_pipeline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "#get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "#import bokeh to enable interactive plots\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import output_notebook, push_notebook, show\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "#import yaml to read in the parameter file\n",
    "import yaml\n",
    "\n",
    "#imports to use RECTE\n",
    "import os\n",
    "from astropy.table import QTable\n",
    "import astropy.units as u\n",
    "import numpy as np\n",
    "from astropy.io import fits, ascii\n",
    "from astropy.table import Table, join\n",
    "import pandas as pd\n",
    "from astropy.time import Time\n",
    "import time\n",
    "\n",
    "#import to copy\n",
    "from copy import deepcopy\n",
    "\n",
    "#modeling light curves\n",
    "from scipy.optimize import curve_fit\n",
    "import batman\n",
    "\n",
    "#to fix errors\n",
    "import pdb\n",
    "\n",
    "#to correct for time differences\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.coordinates import EarthLocation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Array Working RECTE Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python\n",
    "\"\"\"calculate RECTE model using a a template grism Image\n",
    "\"\"\"\n",
    "\n",
    "def RECTE(\n",
    "        cRates,\n",
    "        tExp,\n",
    "        exptime=100.651947,\n",
    "        trap_pop_s=200,\n",
    "        trap_pop_f=0,\n",
    "        dTrap_s=0,\n",
    "        dTrap_f=0,\n",
    "        dt0=0,\n",
    "        lost=0,\n",
    "        mode='staring'\n",
    "):\n",
    "    \"\"\"Hubble Space Telescope ramp effet model\n",
    "    Parameters:\n",
    "    cRates -- intrinsic count rate of each exposures, unit e/s. Is now a 2D array\n",
    "    tExp -- start time of every exposures\n",
    "    expTime -- (default 180 seconds) exposure time of the time series\n",
    "    trap_pop -- (default 0) number of occupied traps at the beginning of the observations\n",
    "    dTrap -- (default [0])number of extra trap added in the gap\n",
    "    between two orbits\n",
    "    dt0 -- (default 0) possible exposures before very beginning, e.g.,\n",
    "    possible guiding adjustment\n",
    "    lost -- (default 0, no lost) proportion of trapped electrons that are not eventually detected\n",
    "    (mode) -- (default scanning, scanning or staring, or others), for scanning mode\n",
    "      observation , the pixel no longer receive photons during the overhead\n",
    "      time, in staring mode, the pixel keps receiving elctrons\n",
    "    \"\"\"\n",
    "    nTrap_s = 1525.38 \n",
    "    eta_trap_s = 0.013318 \n",
    "    tau_trap_s = 1.63e4  # = 1.63e4\n",
    "    nTrap_f = 162.38\n",
    "    eta_trap_f = 0.008407\n",
    "    tau_trap_f = 281.463\n",
    "    \n",
    "    #nTrap_s = 2192  # = 1525.38  # 1320.0\n",
    "    #eta_trap_s = 0.02075  # = 0.013318  # 0.01311\n",
    "    #tau_trap_s = 1.63e4  # = 1.63e4\n",
    "    #nTrap_f = 225.7  # = 162.38\n",
    "    #eta_trap_f = 0.0116  # = 0.008407\n",
    "    #tau_trap_f = 3344  # = 281.463\n",
    "    \n",
    "    # nTrap_s = 1525.38  # 1320.0\n",
    "    # eta_trap_s = 0.013318  # 0.01311\n",
    "    # tau_trap_s = 1.63e4\n",
    "    # nTrap_f = 162.38\n",
    "    # eta_trap_f = 0.008407\n",
    "    # tau_trap_f = 281.463\n",
    "\n",
    "    try:\n",
    "        dTrap_f = itertools.cycle(dTrap_f)\n",
    "        dTrap_s = itertools.cycle(dTrap_s)\n",
    "        dt0 = itertools.cycle(dt0)\n",
    "    except TypeError:\n",
    "        dTrap_f = itertools.cycle([dTrap_f])\n",
    "        dTrap_s = itertools.cycle([dTrap_s])\n",
    "        dt0 = itertools.cycle([dt0])\n",
    "    #create an obsCounts array the same size as the cRates array\n",
    "    obsCounts = np.zeros_like(cRates)\n",
    "    trap_pop_s = min(trap_pop_s, nTrap_s)\n",
    "    trap_pop_f = min(trap_pop_f, nTrap_f)\n",
    "    dEsList = np.zeros(len(tExp))\n",
    "    dEfList = np.zeros(len(tExp))\n",
    "    dt0_i = next(dt0)\n",
    "    #cRates has the time element along the y-direction (the rows) and the pixels data along the x-direction (the columns)\n",
    "    f0 = cRates[0] #grabs the first element(a 1D array) of the 2D array\n",
    "    \n",
    "    c1_s = eta_trap_s * f0 / nTrap_s + 1 / tau_trap_s  # a key factor\n",
    "    c1_f = eta_trap_f * f0 / nTrap_f + 1 / tau_trap_f\n",
    "    \n",
    "    dE0_s = (eta_trap_s * f0 / c1_s - trap_pop_s) * (1 - np.exp(-c1_s * dt0_i))\n",
    "    dE0_f = (eta_trap_f * f0 / c1_f - trap_pop_f) * (1 - np.exp(-c1_f * dt0_i))\n",
    "    \n",
    "    #np.minimum will compare each element of the array to the constant value of nTrap_s returning a minimum of the array element-wise\n",
    "    dE0_s = np.minimum(trap_pop_s + dE0_s, nTrap_s) - trap_pop_s\n",
    "    dE0_f = np.minimum(trap_pop_f + dE0_f, nTrap_f) - trap_pop_f\n",
    "    trap_pop_s = np.minimum(trap_pop_s + dE0_s, nTrap_s)\n",
    "    trap_pop_f = np.minimum(trap_pop_f + dE0_f, nTrap_f)\n",
    "\n",
    "    \n",
    "    #for loop over the time element\n",
    "    for i in range(len(tExp)):\n",
    "        try:\n",
    "            dt = tExp[i+1] - tExp[i]\n",
    "        except IndexError:\n",
    "            dt = exptime\n",
    "        # cRates[i] will sequently grab each element(a 1D array)in the 2D array. \n",
    "        f_i = cRates[i]\n",
    "        c1_s = eta_trap_s * f_i / nTrap_s + 1 / tau_trap_s  # a key factor\n",
    "        c1_f = eta_trap_f * f_i / nTrap_f + 1 / tau_trap_f\n",
    "        # number of trapped electron during one exposure\n",
    "        dE1_s = (eta_trap_s * f_i / c1_s - trap_pop_s) * (1 - np.exp(-c1_s * exptime))\n",
    "        dE1_f = (eta_trap_f * f_i / c1_f - trap_pop_f) * (1 - np.exp(-c1_f * exptime))\n",
    "        dE1_s = np.minimum(trap_pop_s + dE1_s, nTrap_s)- trap_pop_s\n",
    "        dE1_f = np.minimum(trap_pop_f + dE1_f, nTrap_f)- trap_pop_f\n",
    "        trap_pop_s = np.minimum(trap_pop_s + dE1_s, nTrap_s)\n",
    "        trap_pop_f = np.minimum(trap_pop_f + dE1_f, nTrap_f)\n",
    "        \n",
    "        #obsCount for each 1D array element from the 2D array\n",
    "        obsCounts[i] = f_i * exptime - dE1_s - dE1_f\n",
    "        if dt < 5 * exptime:  # whether next exposure is in next batch of exposures\n",
    "            # same orbits\n",
    "            if mode == 'scanning':\n",
    "                # scanning mode, no incoming flux between exposures\n",
    "                dE2_s = - trap_pop_s * (1 - np.exp(-(dt - exptime)/tau_trap_s))\n",
    "                dE2_f = - trap_pop_f * (1 - np.exp(-(dt - exptime)/tau_trap_f))\n",
    "                dEsList[i] = dE1_s + dE2_s\n",
    "                dEfList[i] = dE1_f + dE2_f\n",
    "            elif mode == 'staring':\n",
    "                # for staring mode, there is flux between exposures\n",
    "                dE2_s = (eta_trap_s * f_i / c1_s - trap_pop_s) * (1 - np.exp(-c1_s * (dt - exptime)))\n",
    "                dE2_f = (eta_trap_f * f_i / c1_f - trap_pop_f) * (1 - np.exp(-c1_f * (dt - exptime)))\n",
    "            else:\n",
    "                # others, same as scanning\n",
    "                dE2_s = - trap_pop_s * (1 - np.exp(-(dt - exptime)/tau_trap_s))\n",
    "                dE2_f = - trap_pop_f * (1 - np.exp(-(dt - exptime)/tau_trap_f))\n",
    "            trap_pop_s = np.minimum(trap_pop_s + dE2_s, nTrap_s)\n",
    "            trap_pop_f = np.minimum(trap_pop_f + dE2_f, nTrap_f)\n",
    "        elif dt < 1200:\n",
    "            trap_pop_s = np.minimum(trap_pop_s * np.exp(-(dt-exptime)/tau_trap_s),nTrap_s)\n",
    "            trap_pop_f = np.minimum(trap_pop_f * np.exp(-(dt-exptime)/tau_trap_f),nTrap_f)\n",
    "        else:\n",
    "            # switch orbit\n",
    "            dt0_i = next(dt0)\n",
    "            trap_pop_s = np.minimum(trap_pop_s * np.exp(-(dt-exptime-dt0_i)/tau_trap_s) + next(dTrap_s), nTrap_s)\n",
    "            trap_pop_f = np.minimum(trap_pop_f * np.exp(-(dt-exptime-dt0_i)/tau_trap_f) + next(dTrap_f), nTrap_f)\n",
    "            f_i = cRates[i+1]\n",
    "            c1_s = eta_trap_s * f_i / nTrap_s + 1 / tau_trap_s  # a key factor\n",
    "            c1_f = eta_trap_f * f_i / nTrap_f + 1 / tau_trap_f\n",
    "            dE3_s = (eta_trap_s * f_i / c1_s - trap_pop_s) * (1 - np.exp(-c1_s * dt0_i))\n",
    "            dE3_f = (eta_trap_f * f_i / c1_f - trap_pop_f) * (1 - np.exp(-c1_f * dt0_i))\n",
    "            dE3_s = np.minimum(trap_pop_s + dE3_s, nTrap_s) - trap_pop_s\n",
    "            dE3_f = np.minimum(trap_pop_f + dE3_f, nTrap_f) - trap_pop_f\n",
    "            trap_pop_s = np.minimum(trap_pop_s + dE3_s, nTrap_s)\n",
    "            trap_pop_f = np.minimum(trap_pop_f + dE3_f, nTrap_f)\n",
    "        trap_pop_s = np.maximum(trap_pop_s, 0)\n",
    "        trap_pop_f = np.maximum(trap_pop_f, 0)\n",
    "\n",
    "    return obsCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RECTEMulti(template,\n",
    "                 variability,\n",
    "                 tExp,\n",
    "                 exptime,\n",
    "                 trap_pop_s=200,\n",
    "                 trap_pop_f=0,\n",
    "                 dTrap_s=0,\n",
    "                 dTrap_f=0,\n",
    "                 dt0=0,\n",
    "                 mode='staring'):\n",
    "    \"\"\"loop through every pixel in the template\n",
    "    calculate for 6 orbit\n",
    "    return\n",
    "    model light curves\n",
    "    template -- a template image of the input sereis\n",
    "    variablities -- normalized model light curves\n",
    "    tExp -- starting times of each exposure of the time resolved observations\n",
    "    trap_pop_s -- (default=0)number of initially occupied traps -- slow poplulation\n",
    "    trap_pop_f -- number of initially occupied traps -- fast poplulation\n",
    "    dTrap_s -- (default=0, can be either number or list) number of extra\n",
    "        trapped charge carriers added in the middle of two orbits\n",
    "        -- slow population. If it is a number, it assumes that all\n",
    "        the extra added trap charge carriers are the same\n",
    "    dTrap_f -- (default=0, can be either number or list) number of extra\n",
    "         trapped charge carriers added in the middle of two orbits\n",
    "        -- fast population. If it is a number, it assumes that all\n",
    "        the extra added trap charge carriers are the same\n",
    "    \"\"\"\n",
    "    #multiplies outter product of two vectors out[i, j] = variability[i] * template[j]\n",
    "    rates2D = np.outer(variability,template)\n",
    "    outSpec = RECTE(\n",
    "            rates2D,\n",
    "            tExp,\n",
    "            exptime,\n",
    "            trap_pop_s,\n",
    "            trap_pop_f,\n",
    "            dTrap_s=dTrap_s,\n",
    "            dTrap_f=dTrap_f,\n",
    "            dt0=dt0,\n",
    "            lost=0,\n",
    "            mode=mode)\n",
    "    #transpose the array in order to sum along the zero axis. \n",
    "    return np.sum(outSpec.transpose(),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[307]:\n",
    "\n",
    "\n",
    "def calculate_correction(csv_file,median_image):\n",
    "    '''\n",
    "    Calculate the RECTE ramp correction \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    csv_file: file\n",
    "        Read in a csv file with all the required data. \n",
    "        \n",
    "    median_image: fits file\n",
    "        Read in a fits file of the median image         \n",
    "        '''\n",
    "    info = pd.read_csv(\n",
    "        csv_file,\n",
    "        parse_dates=True,\n",
    "        index_col='Time (UTC)')\n",
    "    info['Time'] = np.float32(info.index - info.index.values[0]) / 1e9\n",
    "    grismInfo = info[info['Filter'] == 'G141']\n",
    "    exptime = grismInfo['Exp Time'].values[0]\n",
    "    tExp = grismInfo['Time'].values\n",
    "    tExp = tExp - tExp[0]\n",
    "    # cRates = np.ones(len(LC)) * LC.mean() * 1.002\n",
    "    cRates = np.ones(len(tExp))\n",
    "    variability = cRates / cRates.mean()\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    im = fits.getdata(median_image)\n",
    "   # bbox = [0, 128, 59, 89]  # define the bounding box of the area of interest\n",
    "    bbox = [0, 128, 69, 79]\n",
    "    xList = np.arange(bbox[0], bbox[1])\n",
    "    ramps = np.zeros((len(xList), len(tExp)))\n",
    "    dTrap_fList = [0]\n",
    "    dTrap_sList = [0]\n",
    "    dtList = [0]\n",
    "    full_well = 8e4\n",
    "    for i, x in enumerate(xList):\n",
    "        template = im[bbox[2]:bbox[3], x] \n",
    "        for j, flux in enumerate(template):\n",
    "            if flux * exptime > full_well:\n",
    "                template[j] = full_well / exptime\n",
    "\n",
    "        obs = RECTEMulti(template, variability, tExp, exptime,\n",
    "                         dTrap_f=dTrap_fList,\n",
    "                         dTrap_s=dTrap_sList,\n",
    "                         trap_pop_f=0,\n",
    "                         trap_pop_s=200,\n",
    "                         dt0=dtList,\n",
    "                         mode='staring')\n",
    "        obs = obs / exptime / np.nansum(template)\n",
    "        # ax.plot(tExp, obs, '.', color='0.8', ms=1)\n",
    "        ramps[i, :] = obs\n",
    "    ax.plot(tExp, ramps[30, :], '.')\n",
    "    #plt.show()\n",
    "    return ramps\n",
    "\n",
    "\n",
    "# In[308]:\n",
    "\n",
    "\n",
    "def calculate_correction_fast(x,exptime,median_image,dtrap_s=[0],trap_pop_s=200,xList=np.arange(0,13)):\n",
    "    '''\n",
    "    Calculate the RECTE ramp correction: fast-version \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x:  \n",
    "       Time in JD\n",
    "         \n",
    "    exptime: int\n",
    "        Defines the exposure time for the observation\n",
    "        \n",
    "     median_image: fits file\n",
    "        Read in a fits file of the median image\n",
    "    \n",
    "    trap_pop_s: int\n",
    "        (default=0)number of initially occupied traps -- slow poplulation\n",
    "   \n",
    "    dTrap_s: int\n",
    "        (default=0, can be either number or list) number of extra\n",
    "        trapped charge carriers added in the middle of two orbits\n",
    "        -- slow population. If it is a number, it assumes that all\n",
    "        the extra added trap charge carriers are the same\n",
    "        \n",
    "    xList: list \n",
    "        A list on the range of Dispersion\n",
    "    \n",
    "    '''\n",
    "    tExp=(x-x[0])*3600*24\n",
    "    # cRates = np.ones(len(LC)) * LC.mean() * 1.002\n",
    "    cRates = np.ones(len(tExp))\n",
    "    variability = cRates / cRates.mean()\n",
    "    im = median_image\n",
    "   # bbox = [0, 128, 59, 89]  # define the bounding box of the area of interest\n",
    "    bbox = [0, 128, 69, 79]\n",
    "    xList = xList\n",
    "    ramps = np.zeros((len(xList), len(tExp)))\n",
    "    dTrap_fList = [0]\n",
    "    dTrap_sList = [0]\n",
    "    dtList = [0]\n",
    "    full_well = 8e4\n",
    "    \n",
    "    for i, x in enumerate(xList):\n",
    "        template = im[bbox[2]:bbox[3], x]\n",
    "        \n",
    "        #defining the high points in the template image\n",
    "        high_pts = template > (full_well / exptime)\n",
    "        template[high_pts] = full_well / exptime\n",
    "                \n",
    "                \n",
    "        obs = RECTEMulti(template, variability, tExp, exptime,\n",
    "                         dTrap_f=dTrap_fList,\n",
    "                         dTrap_s=dtrap_s,\n",
    "                         trap_pop_f=0,\n",
    "                         trap_pop_s=trap_pop_s,\n",
    "                         dt0=dtList,\n",
    "                         mode='staring')\n",
    "        obs = obs / exptime / np.nansum(template)\n",
    "        # ax.plot(tExp, obs, '.', color='0.8', ms=1)\n",
    "        ramps[i, :] = obs\n",
    "    return ramps\n",
    "\n",
    "\n",
    "# In[309]:\n",
    "\n",
    "\n",
    "def charge_correction(self,ramps):\n",
    "    '''\n",
    "    Returns the ramp corrected flux data \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    ramps:\n",
    "        Returns the data for correcting ramp effect. \n",
    "        \n",
    "    '''\n",
    "    HDUList = fits.open(self.specFile)\n",
    "    origData = HDUList['OPTIMAL SPEC'].data\n",
    "    \n",
    "    newData = deepcopy(origData)\n",
    "    newData[0,:,:] = origData[0,:,:] / ramps.transpose()\n",
    "    \n",
    "    HDUList['OPTIMAL SPEC'].data = newData\n",
    "    correctedSpecFile = os.path.splitext(self.specFile)[0]+'_corrected.fits'\n",
    "    HDUList.writeto(correctedSpecFile,overwrite=True)\n",
    "    \n",
    "    new_param = deepcopy(self.param)\n",
    "    new_param['srcNameShort'] = 'corot1_corrected'\n",
    "    new_spec = spec_pipeline.spec(directParam=new_param)\n",
    "    new_spec.specFile = correctedSpecFile\n",
    "\n",
    "    \n",
    "    return newData,new_spec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_v1= 'visit1'\n",
    "spec_v2= 'visit2'\n",
    "spec_v3= 'visit3'\n",
    "spec_v4= 'visit4'\n",
    "\n",
    "\n",
    "#read in result files\n",
    "corot1_visit1_results = pd.read_csv('corot1_visit1_results.csv')\n",
    "corot1_visit2_results = pd.read_csv('corot1_visit2_results.csv')\n",
    "corot1_visit3_results = pd.read_csv('corot1_visit3_results.csv')\n",
    "corot1_visit4_results = pd.read_csv('corot1_visit4_results.csv')\n",
    "\n",
    "#read in median fit files\n",
    "median_image_v1 = fits.getdata('corot1_visit1_median_image.fits')\n",
    "median_image_v2 = fits.getdata('corot1_visit2_median_image.fits')\n",
    "median_image_v3 = fits.getdata('corot1_visit3_median_image.fits')\n",
    "median_image_v4 = fits.getdata('corot1_visit4_median_image.fits')\n",
    "\n",
    "#extract times\n",
    "time_v1 = corot1_visit1_results['Time'].values\n",
    "time_v2 = corot1_visit2_results['Time'].values\n",
    "time_v3 = corot1_visit3_results['Time'].values\n",
    "time_v4 = corot1_visit4_results['Time'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RECTE_ramp_profile_check(self, xdata, median_image, exptime=100.65194699999999):\n",
    "    import time\n",
    "    \n",
    "    \n",
    "    #read in gold standard ramp profile\n",
    "    ramp_profile_gold = 'test_ramp_profiles/gold_ramps_visit_{}_nbins{}.csv'.format(self,1)\n",
    "    if (os.path.exists(ramp_profile_gold) == True ):\n",
    "            dat_gold = ascii.read(ramp_profile_gold)\n",
    "            ramp_model_gold = np.array(dat_gold['ramp_model'])\n",
    "    else: \n",
    "        print(\"Path not found\")\n",
    "        \n",
    "    #start time\n",
    "    start = time.time()\n",
    "        \n",
    "    #calculate ramp profile\n",
    "    ramp = calculate_correction_fast(xdata,exptime,median_image,dtrap_s=[45],trap_pop_s=200,xList=np.arange(40,48))\n",
    "    ramp_model = np.mean(ramp,axis=0)\n",
    "    \n",
    "    #end time\n",
    "    end = time.time()\n",
    "\n",
    "    #Check if the profiles match\n",
    "    if np.allclose(ramp_model_gold,ramp_model,rtol=1e-15) == False:\n",
    "            raise Exception(\"Ramp-Profiles Don't Match\")\n",
    "    else:\n",
    "        print(\"Ramp-Profiles Match\")\n",
    "        \n",
    "    # total time taken\n",
    "    print(f\"Runtime of the program is {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp-Profiles Match\n",
      "Runtime of the program is 0.09719657897949219 seconds\n",
      "Ramp-Profiles Match\n",
      "Runtime of the program is 0.0930633544921875 seconds\n",
      "Ramp-Profiles Match\n",
      "Runtime of the program is 0.09328985214233398 seconds\n",
      "Ramp-Profiles Match\n",
      "Runtime of the program is 0.09157657623291016 seconds\n"
     ]
    }
   ],
   "source": [
    "#Visit 1,2,3,&4 Ramp-Profiles\n",
    "ramp_v1=RECTE_ramp_profile_check(spec_v1, time_v1, median_image_v1)\n",
    "ramp_v2=RECTE_ramp_profile_check(spec_v2, time_v2, median_image_v2)\n",
    "ramp_v3=RECTE_ramp_profile_check(spec_v3, time_v3, median_image_v3)\n",
    "ramp_v4=RECTE_ramp_profile_check(spec_v4, time_v4, median_image_v4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime of the program is 1.5186371803283691 seconds\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "ramp = calculate_correction_fast(time_v1,100.65194699999999,median_image_v1,dtrap_s=[0],trap_pop_s=200,xList=np.arange(0,128))\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Runtime of the program is {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST FUNCTIONS (DO NOT RUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python\n",
    "\"\"\"calculate RECTE model using a a template grism Image\n",
    "\"\"\"\n",
    "\n",
    "def RECTE(\n",
    "        cRates,\n",
    "        tExp,\n",
    "        exptime=100.651947,\n",
    "        trap_pop_s=200,\n",
    "        trap_pop_f=0,\n",
    "        dTrap_s=0,\n",
    "        dTrap_f=0,\n",
    "        dt0=0,\n",
    "        lost=0,\n",
    "        mode='staring'\n",
    "):\n",
    "    \"\"\"Hubble Space Telescope ramp effet model\n",
    "    Parameters:\n",
    "    cRates -- intrinsic count rate of each exposures, unit e/s\n",
    "    tExp -- start time of every exposures\n",
    "    expTime -- (default 180 seconds) exposure time of the time series\n",
    "    trap_pop -- (default 0) number of occupied traps at the beginning of the observations\n",
    "    dTrap -- (default [0])number of extra trap added in the gap\n",
    "    between two orbits\n",
    "    dt0 -- (default 0) possible exposures before very beginning, e.g.,\n",
    "    possible guiding adjustment\n",
    "    lost -- (default 0, no lost) proportion of trapped electrons that are not eventually detected\n",
    "    (mode) -- (default scanning, scanning or staring, or others), for scanning mode\n",
    "      observation , the pixel no longer receive photons during the overhead\n",
    "      time, in staring mode, the pixel keps receiving elctrons\n",
    "    \"\"\"\n",
    "    nTrap_s = 1525.38 \n",
    "    eta_trap_s = 0.013318 \n",
    "    tau_trap_s = 1.63e4  # = 1.63e4\n",
    "    nTrap_f = 162.38\n",
    "    eta_trap_f = 0.008407\n",
    "    tau_trap_f = 281.463\n",
    "    \n",
    "    #nTrap_s = 2192  # = 1525.38  # 1320.0\n",
    "    #eta_trap_s = 0.02075  # = 0.013318  # 0.01311\n",
    "    #tau_trap_s = 1.63e4  # = 1.63e4\n",
    "    #nTrap_f = 225.7  # = 162.38\n",
    "    #eta_trap_f = 0.0116  # = 0.008407\n",
    "    #tau_trap_f = 3344  # = 281.463\n",
    "    \n",
    "    # nTrap_s = 1525.38  # 1320.0\n",
    "    # eta_trap_s = 0.013318  # 0.01311\n",
    "    # tau_trap_s = 1.63e4\n",
    "    # nTrap_f = 162.38\n",
    "    # eta_trap_f = 0.008407\n",
    "    # tau_trap_f = 281.463\n",
    "\n",
    "    try:\n",
    "        dTrap_f = itertools.cycle(dTrap_f)\n",
    "        dTrap_s = itertools.cycle(dTrap_s)\n",
    "        dt0 = itertools.cycle(dt0)\n",
    "    except TypeError:\n",
    "        dTrap_f = itertools.cycle([dTrap_f])\n",
    "        dTrap_s = itertools.cycle([dTrap_s])\n",
    "        dt0 = itertools.cycle([dt0])\n",
    "    obsCounts = np.zeros(len(tExp))\n",
    "    trap_pop_s = min(trap_pop_s, nTrap_s)\n",
    "    trap_pop_f = min(trap_pop_f, nTrap_f)\n",
    "    dEsList = np.zeros(len(tExp))\n",
    "    dEfList = np.zeros(len(tExp))\n",
    "    dt0_i = next(dt0)\n",
    "    # do we want cRates to evaluate column by column or do we want it to read the entire image in one go? \n",
    "    #if we wanted to go columns by column we could do cRates[:,0] #grab all the rows but only the first column\n",
    "    # if we want to read in the entire thing. Lets try to add up the entire cRates array into one number sum(map(sum,cRates)?\n",
    "    f0 = cRates[:,0] #grab all the array\n",
    "    \n",
    "    #eta_trap_s a const times an array instead of another value. c1_s is an array now\n",
    "    c1_s = eta_trap_s * f0 / nTrap_s + 1 / tau_trap_s  # a key factor\n",
    "    #c1_f is an array now\n",
    "    c1_f = eta_trap_f * f0 / nTrap_f + 1 / tau_trap_f\n",
    "    \n",
    "    #here it tries to subtract a const value from what is now an array it will subtract the constant from eahc element. dE)_s is now an array\n",
    "    dE0_s = (eta_trap_s * f0 / c1_s - trap_pop_s) * (1 - np.exp(-c1_s * dt0_i))\n",
    "    #dE0_f is now an array as well\n",
    "    dE0_f = (eta_trap_f * f0 / c1_f - trap_pop_f) * (1 - np.exp(-c1_f * dt0_i))\n",
    "    \n",
    "    #by default, np.min flattens the array and finds minimum. This is finding the min so dE0_s is now a float/int \n",
    "    dE0_s = np.minimum(trap_pop_s + dE0_s, np.full((len(cRates[:,0]), ), nTrap_s)) - trap_pop_s\n",
    "    #this is nwow a float/int\n",
    "    dE0_f = np.minimum(trap_pop_f + dE0_f, np.full((len(cRates[:,0]), ), nTrap_f)) - trap_pop_f\n",
    "    #these are float/int values now\n",
    "    trap_pop_s = np.minimum(trap_pop_s + dE0_s, np.full((len(cRates[:,0]), ), nTrap_s))\n",
    "    trap_pop_f = np.minimum(trap_pop_f + dE0_f, np.full((len(cRates[:,0]), ), nTrap_f))\n",
    "    \n",
    "    for i in range(len(tExp)):\n",
    "        try:\n",
    "            dt = tExp[i+1] - tExp[i]\n",
    "        except IndexError:\n",
    "            dt = exptime\n",
    "        f_i = cRates[:,i]\n",
    "        c1_s = eta_trap_s * f_i / nTrap_s + 1 / tau_trap_s  # a key factor\n",
    "        c1_f = eta_trap_f * f_i / nTrap_f + 1 / tau_trap_f\n",
    "        # number of trapped electron during one exposure\n",
    "        dE1_s = (eta_trap_s * f_i / c1_s - trap_pop_s) * (1 - np.exp(-c1_s * exptime))\n",
    "        dE1_f = (eta_trap_f * f_i / c1_f - trap_pop_f) * (1 - np.exp(-c1_f * exptime))\n",
    "        dE1_s = np.minimum(trap_pop_s + dE1_s, np.full((len(cRates[:,i]), ), nTrap_s)) - trap_pop_s\n",
    "        dE1_f = np.minimum(trap_pop_f + dE1_f, np.full((len(cRates[:,i]), ), nTrap_f)) - trap_pop_f\n",
    "        trap_pop_s = np.minimum(trap_pop_s + dE1_s, np.full((len(cRates[:,i]), ), nTrap_s))\n",
    "        trap_pop_f = np.minimum(trap_pop_f + dE1_f, np.full((len(cRates[:,i]), ), nTrap_f))\n",
    "        #obsCount for each column\n",
    "        obsCounts[:,i] = f_i * exptime - dE1_s - dE1_f\n",
    "        if dt < 5 * exptime:  # whether next exposure is in next batch of exposures\n",
    "            # same orbits\n",
    "            if mode == 'scanning':\n",
    "                # scanning mode, no incoming flux between exposures\n",
    "                dE2_s = - trap_pop_s * (1 - np.exp(-(dt - exptime)/tau_trap_s))\n",
    "                dE2_f = - trap_pop_f * (1 - np.exp(-(dt - exptime)/tau_trap_f))\n",
    "                dEsList[i] = dE1_s + dE2_s\n",
    "                dEfList[i] = dE1_f + dE2_f\n",
    "            elif mode == 'staring':\n",
    "                # for staring mode, there is flux between exposures\n",
    "                dE2_s = (eta_trap_s * f_i / c1_s - trap_pop_s) * (1 - np.exp(-c1_s * (dt - exptime)))\n",
    "                dE2_f = (eta_trap_f * f_i / c1_f - trap_pop_f) * (1 - np.exp(-c1_f * (dt - exptime)))\n",
    "            else:\n",
    "                # others, same as scanning\n",
    "                dE2_s = - trap_pop_s * (1 - np.exp(-(dt - exptime)/tau_trap_s))\n",
    "                dE2_f = - trap_pop_f * (1 - np.exp(-(dt - exptime)/tau_trap_f))\n",
    "            trap_pop_s = np.minimum(trap_pop_s + dE2_s, np.full((len(cRates[:,i]), ), nTrap_s))\n",
    "            trap_pop_f = np.minimum(trap_pop_f + dE2_f, np.full((len(cRates[:,i]), ), nTrap_f))\n",
    "        elif dt < 1200:\n",
    "            trap_pop_s = np.minimum(trap_pop_s * np.exp(-(dt-exptime)/tau_trap_s), np.full((len(cRates[:,i]), ), nTrap_s))\n",
    "            trap_pop_f = np.minimum(trap_pop_f * np.exp(-(dt-exptime)/tau_trap_f), np.full((len(cRates[:,i]), ), nTrap_f))\n",
    "        else:\n",
    "            # switch orbit\n",
    "            dt0_i = next(dt0)\n",
    "            trap_pop_s = np.minimum(trap_pop_s * np.exp(-(dt-exptime-dt0_i)/tau_trap_s) + next(dTrap_s), np.full((len(cRates[:,i]), ), nTrap_s))\n",
    "            trap_pop_f = np.minimum(trap_pop_f * np.exp(-(dt-exptime-dt0_i)/tau_trap_f) + next(dTrap_f), np.full((len(cRates[:,i]), ), nTrap_f))\n",
    "            f_i = cRates[:,i+1]\n",
    "            c1_s = eta_trap_s * f_i / nTrap_s + 1 / tau_trap_s  # a key factor\n",
    "            c1_f = eta_trap_f * f_i / nTrap_f + 1 / tau_trap_f\n",
    "            dE3_s = (eta_trap_s * f_i / c1_s - trap_pop_s) * (1 - np.exp(-c1_s * dt0_i))\n",
    "            dE3_f = (eta_trap_f * f_i / c1_f - trap_pop_f) * (1 - np.exp(-c1_f * dt0_i))\n",
    "            dE3_s = np.minimum(trap_pop_s + dE3_s, np.full((len(cRates[:,i]), ), nTrap_s)) - trap_pop_s\n",
    "            dE3_f = np.minimum(trap_pop_f + dE3_f, np.full((len(cRates[:,i]), ), nTrap_f)) - trap_pop_f\n",
    "            trap_pop_s = np.minimum(trap_pop_s + dE3_s, np.full((len(cRates[:,i]), ), nTrap_s))\n",
    "            trap_pop_f = np.minimum(trap_pop_f + dE3_f, np.full((len(cRates[:,i]), ), nTrap_f))\n",
    "        trap_pop_s = np.maximum(trap_pop_s, 0)\n",
    "        trap_pop_f = np.maximum(trap_pop_f, 0)\n",
    "\n",
    "    return obsCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python\n",
    "\"\"\"calculate RECTE model using a a template grism Image\n",
    "\"\"\"\n",
    "\n",
    "def RECTE(\n",
    "        cRates,\n",
    "        tExp,\n",
    "        exptime=100.651947,\n",
    "        trap_pop_s=200,\n",
    "        trap_pop_f=0,\n",
    "        dTrap_s=0,\n",
    "        dTrap_f=0,\n",
    "        dt0=0,\n",
    "        lost=0,\n",
    "        mode='staring'\n",
    "):\n",
    "    \"\"\"Hubble Space Telescope ramp effet model\n",
    "    Parameters:\n",
    "    cRates -- intrinsic count rate of each exposures, unit e/s\n",
    "    tExp -- start time of every exposures\n",
    "    expTime -- (default 180 seconds) exposure time of the time series\n",
    "    trap_pop -- (default 0) number of occupied traps at the beginning of the observations\n",
    "    dTrap -- (default [0])number of extra trap added in the gap\n",
    "    between two orbits\n",
    "    dt0 -- (default 0) possible exposures before very beginning, e.g.,\n",
    "    possible guiding adjustment\n",
    "    lost -- (default 0, no lost) proportion of trapped electrons that are not eventually detected\n",
    "    (mode) -- (default scanning, scanning or staring, or others), for scanning mode\n",
    "      observation , the pixel no longer receive photons during the overhead\n",
    "      time, in staring mode, the pixel keps receiving elctrons\n",
    "    \"\"\"\n",
    "    nTrap_s = 1525.38 \n",
    "    eta_trap_s = 0.013318 \n",
    "    tau_trap_s = 1.63e4  # = 1.63e4\n",
    "    nTrap_f = 162.38\n",
    "    eta_trap_f = 0.008407\n",
    "    tau_trap_f = 281.463\n",
    "    \n",
    "    #nTrap_s = 2192  # = 1525.38  # 1320.0\n",
    "    #eta_trap_s = 0.02075  # = 0.013318  # 0.01311\n",
    "    #tau_trap_s = 1.63e4  # = 1.63e4\n",
    "    #nTrap_f = 225.7  # = 162.38\n",
    "    #eta_trap_f = 0.0116  # = 0.008407\n",
    "    #tau_trap_f = 3344  # = 281.463\n",
    "    \n",
    "    # nTrap_s = 1525.38  # 1320.0\n",
    "    # eta_trap_s = 0.013318  # 0.01311\n",
    "    # tau_trap_s = 1.63e4\n",
    "    # nTrap_f = 162.38\n",
    "    # eta_trap_f = 0.008407\n",
    "    # tau_trap_f = 281.463\n",
    "\n",
    "    try:\n",
    "        dTrap_f = itertools.cycle(dTrap_f)\n",
    "        dTrap_s = itertools.cycle(dTrap_s)\n",
    "        dt0 = itertools.cycle(dt0)\n",
    "    except TypeError:\n",
    "        dTrap_f = itertools.cycle([dTrap_f])\n",
    "        dTrap_s = itertools.cycle([dTrap_s])\n",
    "        dt0 = itertools.cycle([dt0])\n",
    "    obsCounts = np.zeros(len(tExp))\n",
    "    trap_pop_s = min(trap_pop_s, nTrap_s)\n",
    "    trap_pop_f = min(trap_pop_f, nTrap_f)\n",
    "    dEsList = np.zeros(len(tExp))\n",
    "    dEfList = np.zeros(len(tExp))\n",
    "    dt0_i = next(dt0)\n",
    "    # do we want cRates to evaluate column by column or do we want it to read the entire image in one go? \n",
    "    #if we wanted to go columns by column we could do cRates[:,0] #grab all the rows but only the first column\n",
    "    # if we want to read in the entire thing. Lets try to add up the entire cRates array into one number sum(map(sum,cRates)?\n",
    "    f0 = cRates[0][0] #grab all the array\n",
    "    \n",
    "    #eta_trap_s a const times an array instead of another value. c1_s is an array now\n",
    "    c1_s = eta_trap_s * f0 / nTrap_s + 1 / tau_trap_s  # a key factor\n",
    "    #c1_f is an array now\n",
    "    c1_f = eta_trap_f * f0 / nTrap_f + 1 / tau_trap_f\n",
    "    \n",
    "    #here it tries to subtract a const value from what is now an array it will subtract the constant from eahc element. dE)_s is now an array\n",
    "    dE0_s = (eta_trap_s * f0 / c1_s - trap_pop_s) * (1 - np.exp(-c1_s * dt0_i))\n",
    "    #dE0_f is now an array as well\n",
    "    dE0_f = (eta_trap_f * f0 / c1_f - trap_pop_f) * (1 - np.exp(-c1_f * dt0_i))\n",
    "    \n",
    "    #by default, np.min flattens the array and finds minimum. This is finding the min so dE0_s is now a float/int \n",
    "    dE0_s = np.minimum(np.amin(trap_pop_s + dE0_s,axis=0), np.full((1,len(cRates[:,:][0])), nTrap_s)) - trap_pop_s\n",
    "    #this is nwow a float/int\n",
    "    dE0_f = np.minimum(np.amin(trap_pop_f + dE0_f,axis=0), np.full((1,len(cRates[:,:][0])), nTrap_f)) - trap_pop_f\n",
    "    #these are float/int values now\n",
    "    trap_pop_s = np.minimum(np.amin(trap_pop_s + dE0_s,axis=0), np.full((1,len(cRates[:,:][0])), nTrap_s))\n",
    "    trap_pop_f = np.minimum(np.amin(trap_pop_f + dE0_f,axis=0), np.full((1,len(cRates[:,:][0])), nTrap_f))\n",
    "\n",
    "    for i in range(cRates.shape[0]):\n",
    "        try:\n",
    "            dt = tExp[i+1] - tExp[i]\n",
    "        except IndexError:\n",
    "            dt = exptime\n",
    "        f_i = cRates[i,:]\n",
    "        c1_s = eta_trap_s * f_i / nTrap_s + 1 / tau_trap_s  # a key factor\n",
    "        c1_f = eta_trap_f * f_i / nTrap_f + 1 / tau_trap_f\n",
    "        # number of trapped electron during one exposure\n",
    "        dE1_s = (eta_trap_s * f_i / c1_s - trap_pop_s) * (1 - np.exp(-c1_s * exptime))\n",
    "        dE1_f = (eta_trap_f * f_i / c1_f - trap_pop_f) * (1 - np.exp(-c1_f * exptime))\n",
    "        dE1_s = np.minimum(np.amin(trap_pop_s + dE1_s,axis=0), np.full((1,len(cRates[:,:][0])), nTrap_s)) - trap_pop_s\n",
    "        dE1_f = np.minimum(np.amin(trap_pop_f + dE1_f,axis=0), np.full((1,len(cRates[:,:][0])), nTrap_f)) - trap_pop_f\n",
    "        trap_pop_s = np.minimum(np.amin(trap_pop_s + dE1_s,axis=0), np.full((1,len(cRates[:,:][0])), nTrap_s))\n",
    "        trap_pop_f = np.minimum(np.amin(trap_pop_f + dE1_f,axis=0), np.full((1,len(cRates[:,:][0])), nTrap_f))\n",
    "        #obsCount for each column\n",
    "        obsCounts[i] = f_i * exptime - dE1_s - dE1_f\n",
    "        if dt < 5 * exptime:  # whether next exposure is in next batch of exposures\n",
    "            # same orbits\n",
    "            if mode == 'scanning':\n",
    "                # scanning mode, no incoming flux between exposures\n",
    "                dE2_s = - trap_pop_s * (1 - np.exp(-(dt - exptime)/tau_trap_s))\n",
    "                dE2_f = - trap_pop_f * (1 - np.exp(-(dt - exptime)/tau_trap_f))\n",
    "                dEsList[i] = dE1_s + dE2_s\n",
    "                dEfList[i] = dE1_f + dE2_f\n",
    "            elif mode == 'staring':\n",
    "                # for staring mode, there is flux between exposures\n",
    "                dE2_s = (eta_trap_s * f_i / c1_s - trap_pop_s) * (1 - np.exp(-c1_s * (dt - exptime)))\n",
    "                dE2_f = (eta_trap_f * f_i / c1_f - trap_pop_f) * (1 - np.exp(-c1_f * (dt - exptime)))\n",
    "            else:\n",
    "                # others, same as scanning\n",
    "                dE2_s = - trap_pop_s * (1 - np.exp(-(dt - exptime)/tau_trap_s))\n",
    "                dE2_f = - trap_pop_f * (1 - np.exp(-(dt - exptime)/tau_trap_f))\n",
    "            trap_pop_s = np.minimum(np.amin(trap_pop_s + dE2_s,axis=0), np.full((1,len(cRates[:,:][0])), nTrap_s))\n",
    "            trap_pop_f = np.minimum(np.amin(trap_pop_f + dE2_f,axis=0), np.full((1,len(cRates[:,:][0])), nTrap_f))\n",
    "        elif dt < 1200:\n",
    "            trap_pop_s = np.minimum(trap_pop_s * np.exp(-(dt-exptime)/tau_trap_s), np.full((1,len(cRates[:,:][0])), nTrap_s))\n",
    "            trap_pop_f = np.minimum(trap_pop_f * np.exp(-(dt-exptime)/tau_trap_f), np.full((1,len(cRates[:,:][0])), nTrap_f))\n",
    "        else:\n",
    "            # switch orbit\n",
    "            dt0_i = next(dt0)\n",
    "            trap_pop_s = np.minimum(trap_pop_s * np.exp(-(dt-exptime-dt0_i)/tau_trap_s) + next(dTrap_s), np.full((1,len(cRates[:,:][0])), nTrap_s))\n",
    "            trap_pop_f = np.minimum(trap_pop_f * np.exp(-(dt-exptime-dt0_i)/tau_trap_f) + next(dTrap_f), np.full((1,len(cRates[:,:][0])), nTrap_f))\n",
    "            f_i = cRates[i+1,:]\n",
    "            c1_s = eta_trap_s * f_i / nTrap_s + 1 / tau_trap_s  # a key factor\n",
    "            c1_f = eta_trap_f * f_i / nTrap_f + 1 / tau_trap_f\n",
    "            dE3_s = (eta_trap_s * f_i / c1_s - trap_pop_s) * (1 - np.exp(-c1_s * dt0_i))\n",
    "            dE3_f = (eta_trap_f * f_i / c1_f - trap_pop_f) * (1 - np.exp(-c1_f * dt0_i))\n",
    "            dE3_s = np.minimum(np.amin(trap_pop_s + dE3_s,axis=0), np.full((1,len(cRates[:,:][0])), nTrap_s)) - trap_pop_s\n",
    "            dE3_f = np.minimum(np.amin(trap_pop_f + dE3_f,axis=0), np.full((1,len(cRates[:,:][0])), nTrap_f)) - trap_pop_f\n",
    "            trap_pop_s = np.minimum(np.amin(trap_pop_s + dE3_s,axis=0), np.full((1,len(cRates[:,:][0])), nTrap_s))\n",
    "            trap_pop_f = np.minimum(np.amin(trap_pop_f + dE3_f,axis=0), np.full((1,len(cRates[:,:][0])), nTrap_f))\n",
    "        trap_pop_s = np.maximum(trap_pop_s, 0)\n",
    "        trap_pop_f = np.maximum(trap_pop_f, 0)\n",
    "\n",
    "    return obsCounts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
